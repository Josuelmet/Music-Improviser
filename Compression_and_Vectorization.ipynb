{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1387f93-eb54-4b6d-9dad-2db5d4c4c8d6",
   "metadata": {
    "id": "e1387f93-eb54-4b6d-9dad-2db5d4c4c8d6"
   },
   "source": [
    "# Step 1: Compression and Vectorization of Songs\n",
    "\n",
    "References: \n",
    "\n",
    "https://github.com/shubham3121/music-generation-using-rnn \n",
    "\n",
    "https://www.hackerearth.com/blog/developers/jazz-music-using-deep-learning/\n",
    "\n",
    "https://pyguitarpro.readthedocs.io/en/stable/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad10df5b-4fd9-4d25-9bb4-577d91d4631d",
   "metadata": {
    "id": "55d3a53d-b08f-4edc-a37c-faa5a41051aa"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87a0d6de-23af-4d2b-a938-e38414a4f9dc",
   "metadata": {
    "id": "b4e83e4a-1a78-4c3e-8e94-d1e1a13637ef"
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import guitarpro\n",
    "from guitarpro import *\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from _Compressor import compress_track"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cfe3a3-8ed5-45f7-9772-ae6dde06f7d6",
   "metadata": {},
   "source": [
    "## Choose Songs (Make sure to convert to 4/4 before running)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d95c988-10fa-4456-bf15-8349a3a650bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose all songs\n",
    "# songs = glob('*.gp*')\n",
    "\n",
    "# Choose a certain cohort of songs\n",
    "\n",
    "'''\n",
    "filenames = glob('pantera-*.gp*') + \\\n",
    "            glob('dream_theater-*.gp*')\n",
    "'''\n",
    "#filenames = ['korn-freak_on_a_leash.gp5']\n",
    "#filenames = ['metallica-master_of_puppets.gp5']\n",
    "\n",
    "#filenames = glob('metallica-*.gp*')\n",
    "filenames = glob('korn-*.gp*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8269b720-8787-4587-9524-8fe6a4f8649f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tracks: 10\n"
     ]
    }
   ],
   "source": [
    "tracks = []\n",
    "\n",
    "for filename in filenames:\n",
    "    song = guitarpro.parse(filename)\n",
    "    \n",
    "    for track in song.tracks:\n",
    "        if track.isPercussionTrack:\n",
    "            continue\n",
    "        \n",
    "        tracks.append(track)\n",
    "        \n",
    "\n",
    "print(f'Number of tracks: {len(tracks)}')\n",
    "\n",
    "#[print(track.name) for track in tracks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b31ef8f-6f6e-4f6a-adff-897898123c61",
   "metadata": {},
   "source": [
    "## Song Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a43df549-4e6b-4e82-a27b-6564d371afd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of notes:\t 9157\n",
      "Number of unique notes:\t 221\n",
      "Number of removed rest-only measures: 2630\n"
     ]
    }
   ],
   "source": [
    "notes = []\n",
    "\n",
    "num_rest_measures = 0\n",
    "\n",
    "\n",
    "for track in tracks:\n",
    "\n",
    "    compressed_track = compress_track(track)\n",
    "    \n",
    "    # Ignore the current track if it only contains rests.\n",
    "    if all(all(beat[0] == 'rest' for beat in measure) for measure in compressed_track):\n",
    "        continue\n",
    "        \n",
    "    # Add each beat's note to the notes list.\n",
    "    for measure in compressed_track:\n",
    "        \n",
    "        # Skip measures that are only rests.\n",
    "        # TODO: Consider only removing rest measures that occur at least twice in a row.\n",
    "        if all(beat[0] == 'rest' for beat in measure):\n",
    "            num_rest_measures += 1\n",
    "            continue\n",
    "        \n",
    "        for beat in measure:\n",
    "            notes.append(beat)\n",
    "            \n",
    "\n",
    "with open('notes', 'wb') as filepath:\n",
    "    pickle.dump(notes, filepath)\n",
    "    \n",
    "print(f'Number of notes:\\t {len(notes)}')\n",
    "print(f'Number of unique notes:\\t {len(set(notes))}')\n",
    "print(f'Number of removed rest-only measures: {num_rest_measures}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5379bb83-cd2a-4974-9723-7f103cae7ba9",
   "metadata": {},
   "source": [
    "## Song Vectorization and NN Input/Output Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c14a358-afc6-4f0a-a60f-81996a25e3d2",
   "metadata": {},
   "source": [
    "#### prepare_sequences(notes, n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85e05643-a864-465a-95eb-4cef1ebd549c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input and output processed.\n"
     ]
    }
   ],
   "source": [
    "SEQUENCE_LENGTH = 100\n",
    "\n",
    "# The function originally returned (network_input, network_output).\n",
    "\n",
    "n_vocab = len(set(notes))\n",
    "# ^ originally a parameter of the function\n",
    "\n",
    "\n",
    "# def prepare_sequences(notes, n_vocab):\n",
    "\n",
    "# Create a dictionary to map notes to integers\n",
    "note_to_int = dict((note, number) for number, note in enumerate(sorted(set(notes))))\n",
    "int_to_note = {v: k for k, v in note_to_int.items()} # Invert the map\n",
    "\n",
    "network_input = []\n",
    "network_output = []\n",
    "\n",
    "# create input sequences and the corresponding outputs\n",
    "for i in range(0, len(notes) - SEQUENCE_LENGTH, 1):\n",
    "    sequence_in = notes[i: i + SEQUENCE_LENGTH]\n",
    "    sequence_out = notes[i + SEQUENCE_LENGTH]\n",
    "    network_input.append([note_to_int[char] for char in sequence_in])\n",
    "    network_output.append(note_to_int[sequence_out])\n",
    "\n",
    "n_patterns = len(network_input)\n",
    "\n",
    "# reshape the input into a format comatible with LSTM layers \n",
    "network_input = np.reshape(network_input, (n_patterns, SEQUENCE_LENGTH, 1))\n",
    "\n",
    "# normalize input\n",
    "network_input = network_input / float(n_vocab)\n",
    "\n",
    "# one hot encode the output vectors\n",
    "network_output = np_utils.to_categorical(network_output)\n",
    "\n",
    "print('Input and output processed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3d13f84-0ef7-4e67-8e45-cfee873b4e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network data successfully pickled.\n"
     ]
    }
   ],
   "source": [
    "with open('network_data', 'wb') as filepath:\n",
    "    pickle.dump(network_input, filepath)\n",
    "    pickle.dump(network_output, filepath)\n",
    "    pickle.dump(n_vocab, filepath)\n",
    "    \n",
    "print('Network data successfully pickled.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00fd9201-0a45-4835-a525-5132f86bebb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note-to-int dict successfully pickled.\n"
     ]
    }
   ],
   "source": [
    "with open('note_int_conversions', 'wb') as filepath:\n",
    "    pickle.dump(note_to_int, filepath)\n",
    "    pickle.dump(int_to_note, filepath)\n",
    "    \n",
    "print('Note-to-int dict successfully pickled.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe44485-3c5e-4bd8-8a49-b450ea89eb4d",
   "metadata": {},
   "source": [
    "## Visualize some patterns in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fb889ec-2a0c-4a4f-9426-d8f248b24839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 most common values:\n",
      "[#Semitones, duration, isDotted]\n",
      "\n",
      "['0' '8' 'False'] \t 11.5%\n",
      "['0' '16' 'False'] \t 5.8%\n",
      "['10' '8' 'False'] \t 3.6%\n",
      "['5' '8' 'False'] \t 3.5%\n",
      "['3' '8' 'False'] \t 3.3%\n",
      "['7' '8' 'False'] \t 2.9%\n",
      "['2' '8' 'False'] \t 2.7%\n",
      "['12' '8' 'False'] \t 2.4%\n",
      "['0_5' '8' 'False'] \t 2.3%\n",
      "['tied' '8' 'False'] \t 1.8%\n",
      "['0' '32' 'False'] \t 1.8%\n",
      "['rest' '8' 'False'] \t 1.6%\n",
      "['8' '8' 'False'] \t 1.6%\n",
      "['24' '8' 'False'] \t 1.6%\n",
      "['17' '8' 'False'] \t 1.5%\n"
     ]
    }
   ],
   "source": [
    "vals, freq = np.unique([note_to_int[x] for x in notes], return_counts=True)\n",
    "\n",
    "vals = np.array([int_to_note[x] for x in vals])\n",
    "freq = 100 * freq / freq.sum()\n",
    "\n",
    "\n",
    "sort_idx = freq.argsort()[::-1]\n",
    "\n",
    "print('Top 15 most common values:')\n",
    "print('[#Semitones, duration, isDotted]\\n')\n",
    "for idx in sort_idx[:15]:\n",
    "    print(f'{vals[idx]} \\t {freq[idx] :.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8f73556-54b9-4b24-b1f2-a91a7728ed46",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "cutoff = len(notes) // 10\n",
    "plt.figure()\n",
    "plt.plot([note_to_int[x] for x in notes[:cutoff]])\n",
    "plt.figure()\n",
    "plt.plot([note_to_int[x] for x in notes[-cutoff:]])\n",
    "''';"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Metal Music Sampling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
