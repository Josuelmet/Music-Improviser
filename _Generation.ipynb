{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1353041-d939-46a2-a2df-51fcd0bfc7dc",
   "metadata": {},
   "source": [
    "# Metal Music Sampling\n",
    "\n",
    "References: \n",
    "\n",
    "https://github.com/shubham3121/music-generation-using-rnn \n",
    "\n",
    "https://www.hackerearth.com/blog/developers/jazz-music-using-deep-learning/\n",
    "\n",
    "https://pyguitarpro.readthedocs.io/en/stable/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515f0e55-1e24-40ac-9b61-f29842f7c29e",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f38f669c-68f6-49ed-8f65-220e32b7e216",
   "metadata": {},
   "outputs": [],
   "source": [
    "import guitarpro\n",
    "from guitarpro import *\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, LSTM, Dropout, Flatten\n",
    "\n",
    "from _Decompressor import decompress_track"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4933987e-c8b5-491c-a232-08467deeb71c",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e408a14-c598-4145-a63e-f921a301ef68",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 100\n",
    "\n",
    "\n",
    "# PITCH[i] = the pitch associated with midi note number i.\n",
    "# For example, PITCH[69] = 'A4'\n",
    "PITCH = {val : str(GuitarString(number=0, value=val)) for val in range(128)}\n",
    "# MIDI[string] = the midi number associated with the note described by string.\n",
    "# For example, MIDI['A4'] = 69.\n",
    "MIDI  = {str(GuitarString(number=0, value=val)) : val for val in range(128)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034a36de-d670-41a6-981b-169519b21bba",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8ef2eab-df6c-47b0-bcc8-41a7c205310f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('notes', 'rb') as filepath:\n",
    "    notes = pickle.load(filepath)\n",
    "\n",
    "with open('note_int_conversions', 'rb') as filepath:\n",
    "    note_to_int = pickle.load(filepath)\n",
    "    int_to_note = pickle.load(filepath)\n",
    "    \n",
    "n_vocab = len(note_to_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e005305-b642-47d3-a5f2-c0922d5b0f2b",
   "metadata": {},
   "source": [
    "## Model generation function (from _Training.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "139425c7-60a5-429e-94b4-82daf9aec9e5",
   "metadata": {
    "id": "522b0779-93db-421c-bd6d-1c141043de0b"
   },
   "outputs": [],
   "source": [
    "def create_network(network_in, n_vocab): \n",
    "    \"\"\"Create the model architecture\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_shape=network_in.shape[1:], return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(128, return_sequences=True))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8333a8d8-c0cf-4f02-b754-398e78c2ace2",
   "metadata": {},
   "source": [
    "## Note generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5ef8d8d-e059-4243-ac0e-35ba975c4506",
   "metadata": {
    "id": "c233514a-acb8-46b5-b7e4-bafb34604d2b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_inputSequences(notes, note_to_int, n_vocab):\n",
    "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
    "\n",
    "    generation_input = []\n",
    "    for i in range(0, len(notes) - SEQUENCE_LENGTH, 1):\n",
    "        sequence_in = notes[i:i + SEQUENCE_LENGTH]\n",
    "        generation_input.append([note_to_int[char] for char in sequence_in])\n",
    "    \n",
    "    generation_input = np.reshape(generation_input, (len(generation_input), SEQUENCE_LENGTH, 1))\n",
    "    \n",
    "    return (generation_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c0d88ad-a2ae-4942-8842-e8f958fc3f58",
   "metadata": {
    "id": "f5455858-e7c3-4df0-9691-8f182749e2ff"
   },
   "outputs": [],
   "source": [
    "def generate_notes(model, network_input, note_to_int, n_vocab):\n",
    "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
    "    # Pick a random integer\n",
    "    start = np.random.randint(0, len(network_input)-1)\n",
    "\n",
    "    # Invert the note_to_int dictionary to get the int_to_note dictionary.\n",
    "    int_to_note = inv_map = {v: k for k, v in note_to_int.items()}\n",
    "    \n",
    "    # pick a random sequence from the input as a starting point for the prediction\n",
    "    '''\n",
    "    TODO: Look into the pattern generation stuff.\n",
    "    '''\n",
    "    pattern = list(network_input[start])\n",
    "    #pattern = list(np.random.choice(n_vocab, (100,1))) # Generate an iniitial sequence at random from n_vocab.\n",
    "    prediction_output = []\n",
    "    \n",
    "    print('Generating notes........')\n",
    "\n",
    "    # generate 500 notes\n",
    "    for note_index in range(500):\n",
    "        prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
    "        prediction_input = prediction_input / float(n_vocab)\n",
    "\n",
    "        prediction = model.predict(prediction_input, verbose=0)\n",
    "\n",
    "        # Predicted output is the argmax(P(h|D))\n",
    "        index = np.argmax(prediction)\n",
    "        # Mapping the predicted interger back to the corresponding note\n",
    "        result = int_to_note[index]\n",
    "        # Storing the predicted output\n",
    "        prediction_output.append(result)\n",
    "\n",
    "        pattern.append(np.array([index])) # Fixed this code to make sure the new element matched the datatype of the existing elements.\n",
    "        # Next input to the model\n",
    "        pattern = pattern[1:len(pattern)]\n",
    "\n",
    "    print('Notes Generated.')\n",
    "    return prediction_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cdfd413-5e2e-43db-a813-b0669a10e4ec",
   "metadata": {
    "id": "7c2712cc-ed8a-42a9-b85f-c3a0af98173c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating music generation process.......\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "('7_dim5', 8, False)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-018d5e8adf96>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m#network_input = get_inputSequences(notes, pitchnames, n_vocab)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mgeneration_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_inputSequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnotes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnote_to_int\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_vocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mnormalized_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgeneration_input\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_vocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-642b9b5a022c>\u001b[0m in \u001b[0;36mget_inputSequences\u001b[1;34m(notes, note_to_int, n_vocab)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnotes\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mSEQUENCE_LENGTH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0msequence_in\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnotes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mSEQUENCE_LENGTH\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mgeneration_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnote_to_int\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchar\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mchar\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msequence_in\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mgeneration_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgeneration_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgeneration_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSEQUENCE_LENGTH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-642b9b5a022c>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnotes\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mSEQUENCE_LENGTH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0msequence_in\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnotes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mSEQUENCE_LENGTH\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mgeneration_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnote_to_int\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchar\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mchar\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msequence_in\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mgeneration_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgeneration_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgeneration_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSEQUENCE_LENGTH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: ('7_dim5', 8, False)"
     ]
    }
   ],
   "source": [
    "\"\"\" Generate a .gp5 tab file \"\"\"\n",
    "\n",
    "'''\n",
    "#load the notes used to train the model\n",
    "with open('data/notes', 'rb') as filepath:\n",
    "    notes = pickle.load(filepath)\n",
    "\n",
    "# Get all pitch names\n",
    "pitchnames = sorted(set(item for item in notes))\n",
    "# Get all pitch names\n",
    "n_vocab = len(set(notes))\n",
    "'''\n",
    "\n",
    "print('Initiating music generation process.......')\n",
    "\n",
    "#network_input = get_inputSequences(notes, pitchnames, n_vocab)\n",
    "generation_input = get_inputSequences(notes, note_to_int, n_vocab)\n",
    "\n",
    "normalized_input = generation_input / float(n_vocab)\n",
    "model = create_network(normalized_input, n_vocab)\n",
    "print('Loading Model weights.....')\n",
    "model.load_weights('weights.best.music3.hdf5')\n",
    "print('Model Loaded')\n",
    "prediction_output = generate_notes(model, generation_input, note_to_int, n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5645634e-49b4-4941-901c-5690f9b09094",
   "metadata": {},
   "outputs": [],
   "source": [
    "def thirty_seconds_to_duration(count):\n",
    "    if count % 3 == 0:\n",
    "        # If the note is dotted, do 32 / (i * 2/3), and return isDotted = True.\n",
    "        return (48//count, True)\n",
    "    else:\n",
    "        # If the note is not dotted, to 32 / i, and return isDotted = False.\n",
    "        return (32//count, False)\n",
    "\n",
    "def quantize_thirty_seconds(value):\n",
    "\n",
    "    # 32nd-note values of each fundamental type of note (not including 64th-notes, of course).\n",
    "    vals = np.array([32, # whole\n",
    "                     24, # dotted half\n",
    "                     16, # half\n",
    "                     12, # dotted quarter\n",
    "                     8,  # quarter\n",
    "                     6,  # dotted eigth\n",
    "                     4,  # eigth\n",
    "                     3,  # dotted sixteenth\n",
    "                     2,  # sixteenth\n",
    "                     1]) # thirty-second\n",
    "    \n",
    "    list_out = []\n",
    "\n",
    "    for v in vals:\n",
    "        if v <= value:\n",
    "            list_out.append(thirty_seconds_to_duration(v))\n",
    "            value -= v\n",
    "            \n",
    "    return np.array(list_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38e6e12-ed45-4c57-9678-200a0277fabe",
   "metadata": {},
   "source": [
    "## Adjust prediction output to 4/4 time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae6d23d-79d6-4f37-ae22-9acab57c9618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will be the prediction output\n",
    "new_prediction_output = []\n",
    "\n",
    "\n",
    "time = 0\n",
    "for beat in prediction_output:\n",
    "    \n",
    "    # Calculate the fraction of a measure encompassed by the current beat / chord.\n",
    "    beat_time = (1 / beat[1]) * (1 + 0.5 * beat[2])\n",
    "    \n",
    "    # Calculate the fraction of a measure taken up by all notes in the measure.\n",
    "    # Calculate any residual time to see if this measure (in 4/4 time) is longer than 1 measure.\n",
    "    measure_time = time + beat_time\n",
    "    leftover_time = (measure_time) % 1\n",
    "    \n",
    "    # If the measure count (i.e., the measure integer) has changed and there is significant left-over beat time:\n",
    "    if (int(measure_time) > int(time)) and (leftover_time > 1/128):\n",
    "        \n",
    "        # Calculate the initial 32nd notes encompassed by this beat in the current measure.\n",
    "        this_measure_thirty_seconds = int(32 * (1 - time % 1))\n",
    "        # Calculate the remaining 32nd notes encompassed by this beat in the next measure.\n",
    "        next_measure_thirty_seconds = int(32 * leftover_time)\n",
    "        \n",
    "        # Get the Duration object parameters for this measure and the next measure.\n",
    "        this_measure_durations = quantize_thirty_seconds(this_measure_thirty_seconds)\n",
    "        next_measure_durations = quantize_thirty_seconds(next_measure_thirty_seconds)\n",
    "        \n",
    "        \n",
    "        #print(f'{{ {32 / beat[1]}')\n",
    "        for duration_idx, duration in enumerate(this_measure_durations):\n",
    "            time += (1 / duration[0]) * (1 + 0.5 * duration[1])\n",
    "            \n",
    "            #print(time, '\\t', time * 32)\n",
    "                \n",
    "            chord = beat[0] if duration_idx == 0 else 'tied'\n",
    "            \n",
    "            new_prediction_output.append((chord, duration[0], duration[1]))\n",
    "            \n",
    "            \n",
    "        for duration in next_measure_durations:\n",
    "            time += (1 / duration[0]) * (1 + 0.5 * duration[1])\n",
    "            \n",
    "            #print(time, '\\t', time * 32)\n",
    "            \n",
    "            new_prediction_output.append(('tied', duration[0], duration[1]))\n",
    "            \n",
    "               \n",
    "        continue\n",
    "    \n",
    "    \n",
    "    time += beat_time\n",
    "    new_prediction_output.append((beat[0], beat[1], beat[2]))\n",
    "    \n",
    "    #print(time, '\\t', time * 32)\n",
    "\n",
    "\n",
    "'''\n",
    "time = 0\n",
    "time2 = 0\n",
    "idx = 0\n",
    "\n",
    "for idx2, beat2 in enumerate(new_prediction_output[:100]):\n",
    "    beat = prediction_output[idx]\n",
    "    \n",
    "    if time == time2:\n",
    "        print(beat[0], '\\t', time, '\\t\\t', beat2[0], '\\t', time2)\n",
    "        \n",
    "        idx += 1\n",
    "        \n",
    "        time += (1 / beat[1]) * (1 + 0.5 * beat[2])\n",
    "    \n",
    "    else:\n",
    "        print('\\t\\t\\t\\t', beat2[0], '\\t', time2)\n",
    "\n",
    "    \n",
    "    \n",
    "    time2 += (1 / beat2[1]) * (1 + 0.5 * beat2[2])\n",
    "''';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebf692b-e536-4b22-ab6d-18787b4d04c7",
   "metadata": {},
   "source": [
    "## Separate prediction output notes into measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdeb980-d2e1-4cdd-8dcc-b8e91d37ee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the previously calculated cumulative time as the number of measures in the new 4/4 song.\n",
    "num_measures = int(np.ceil(time))\n",
    "\n",
    "song = np.empty(num_measures, dtype=object)\n",
    "\n",
    "time = 0\n",
    "m_idx = 0\n",
    "\n",
    "timestamps = []\n",
    "\n",
    "for beat in new_prediction_output:\n",
    "    #print(time)\n",
    "    timestamps.append(time)\n",
    "    \n",
    "    m_idx = int(time)\n",
    "    \n",
    "    if song[m_idx] is None:\n",
    "        \n",
    "        song[m_idx] = [beat]\n",
    "    else:\n",
    "        song[m_idx].append(beat)\n",
    "    \n",
    "    \n",
    "    time += (1 / beat[1]) * (1 + 0.5 * beat[2])\n",
    "    \n",
    "    \n",
    "print(f'4/4 adjusted correctly: {set(range(num_measures)).issubset(set(timestamps))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0ac63c-8deb-4bce-9f7e-e098149e22f1",
   "metadata": {},
   "source": [
    "## Figure out the necessary guitar tuning for the produced song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f0fba7-dcc3-4b61-8088-98ea71b9eb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the tuning (i.e., the lowest note) of the song:\n",
    "\n",
    "'''\n",
    "pitchnames = set([x[0] for x in prediction_output])\n",
    "pitchnames.discard('rest')\n",
    "pitchnames.discard('tied')\n",
    "pitchnames.discard('dead')\n",
    "\n",
    "\n",
    "# Standard tuning\n",
    "tuning = {1: MIDI['E4'],\n",
    "          2: MIDI['B3'],\n",
    "          3: MIDI['G3'],\n",
    "          4: MIDI['D3'],\n",
    "          5: MIDI['A2'],\n",
    "          6: MIDI['E2']}\n",
    "\n",
    "# Get the lowest note in the output.\n",
    "# The highest tuning allowed will be standard tuning.\n",
    "lowest_note = min([MIDI[x.split('_')[0]] for x in pitchnames])\n",
    "lowest_note = min(lowest_note, MIDI['E2'])\n",
    "\n",
    "if lowest_note <= MIDI['B1']:\n",
    "    # 7-string guitar case\n",
    "    tuning[7] = MIDI['B1']\n",
    "    drop = MIDI['B1'] - lowest_note\n",
    "else:\n",
    "    # drop the tuning by however much is necessary.\n",
    "    drop = MIDI['E2'] - lowest_note\n",
    "    \n",
    "tuning = {k: v - drop for k, v in tuning.items()}\n",
    "tuning\n",
    "'''\n",
    "\n",
    "# Standard tuning\n",
    "tuning = {1: MIDI['E4'],\n",
    "          2: MIDI['B3'],\n",
    "          3: MIDI['G3'],\n",
    "          4: MIDI['D3'],\n",
    "          5: MIDI['A2'],\n",
    "          6: MIDI['E2']}\n",
    "tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404c4329-7a8c-47fd-a57b-cb9c7fc27d7a",
   "metadata": {},
   "source": [
    "## Lastly, save the song to a .gp5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caa35ce-2b3a-4f46-8be6-c1ae376174a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "guitarpro.write(decompress_track(song, tuning), '_generation.gp5')\n",
    "print('Finished')\n",
    "\n",
    "'''\n",
    "TODO: Find out which song / where test sequence sources are coming from.\n",
    "\n",
    "TODO: Normalize sequences based on lowest tuning notes to reduce overfitting.\n",
    "TODO: After implementing tuning normalization, decide the tuning of the generated song based on the tuning of the input sequence.\n",
    "\n",
    "TODO: Consider filtering out bass parts.\n",
    "\n",
    "TODO: Train with a wider variety of songs once the generation process has been examined.\n",
    "TODO: If training does not yield true creativity, try generating sequences using the random sequence initialization.\n",
    "''';"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
